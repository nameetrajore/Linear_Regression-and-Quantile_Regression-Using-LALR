{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "oAsFIu0ONwPH"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import numpy as np\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "colab_type": "code",
        "id": "RQMgBe97OJ23",
        "outputId": "a3b6814c-8511-4abe-cd02-b47503734e40"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import boston_housing\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = boston_housing.load_data()\n",
        "x_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "colab_type": "code",
        "id": "RF4ihRJuB_Xd",
        "outputId": "e8aceb19-c719-4f03-aa2c-78b2ba5a584d"
      },
      "outputs": [],
      "source": [
        "y_train = np.expand_dims(y_train,axis=1)\n",
        "y_test = np.expand_dims(y_test,axis=1)\n",
        "print(y_train.shape,y_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "XLlKtDWij3cY"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "9GxE6V5nj-Ww"
      },
      "outputs": [],
      "source": [
        "scaler.fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "USFy1R_6kFX0"
      },
      "outputs": [],
      "source": [
        "scaler.fit(y_train)\n",
        "y_train = scaler.transform(y_train)\n",
        "y_test = scaler.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "iInZEE-6kQ-V"
      },
      "outputs": [],
      "source": [
        "# scaler.fit(x_test)\n",
        "# x_test = scaler.transform(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "i3VIP8j5kRAh"
      },
      "outputs": [],
      "source": [
        "# scaler.fit(y_test)\n",
        "# y_test = scaler.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "zIHnjRr8ORuF"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(32, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(20 ,activation='relu'))\n",
        "model.add(layers.Dropout(0.3))\n",
        "model.add(layers.Dense(1,activation=keras.activations.softsign))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Qr0obLgpOU4C"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "func = K.function([model.layers[0].input], [model.layers[-2].output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "4bGBb4PnOZWK"
      },
      "outputs": [],
      "source": [
        "lrs = []\n",
        "K1 = 0.\n",
        "batch_size=4\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wuK-XisyOb1x"
      },
      "outputs": [],
      "source": [
        "def lr_schedule(epoch):\n",
        "    global K1\n",
        "\n",
        "    Kz = 0.\n",
        "    \n",
        "    for i in tqdm(range((len(x_train) - 1) // batch_size + 1)):\n",
        "        start_i = i * batch_size\n",
        "        end_i = start_i + batch_size\n",
        "        xb = x_train[start_i:end_i]\n",
        "    \t\n",
        "        tmp = np.array(func([xb]))\n",
        "        activ = np.linalg.norm(tmp)\n",
        "        \n",
        "        if activ > Kz:\n",
        "            Kz = activ\n",
        "    print(\"The value of K_z is \",Kz)\n",
        "    K1 = (1/batch_size)*(Kz)*max(q,1-q)\n",
        "    lr = 1 / K1\n",
        "    lrs.append(lr)\n",
        "    print('Epoch', epoch, 'LR =', lr)\n",
        "    return lr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OQyqdSKYPb2T"
      },
      "outputs": [],
      "source": [
        "lr_scheduler = LearningRateScheduler(lr_schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "ZRUsWonLQQ-i"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "def tilted_loss(q,y,f):\n",
        "    e = (y-f)\n",
        "    return K.mean(K.maximum(q*e, (q-1)*e), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "jj6-sRUsRWbd"
      },
      "outputs": [],
      "source": [
        "model_upper = models.Sequential()\n",
        "model_upper.add(layers.Dense(32, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model_upper.add(layers.Dense(20 ,activation='relu'))\n",
        "model_upper.add(layers.Dense(1,activation=keras.activations.softsign))\n",
        "q = 0.95\n",
        "model_upper.compile(loss=lambda y,f: tilted_loss(q,y,f), optimizer=keras.optimizers.SGD())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "q5pxq0OOUx1w",
        "outputId": "2fea467b-f9f3-48d2-94c7-e03c95694065"
      },
      "outputs": [],
      "source": [
        "history_upper=model_upper.fit(x_train, y_train, epochs = 1000, batch_size = 4,validation_data=(x_test,y_test),callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "colab_type": "code",
        "id": "LVA6kYxjWR84",
        "outputId": "c2aa2fec-d657-47fa-ea21-8b8882e8ea8f"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "loss = history_upper.history['loss']\n",
        "val_loss = history_upper.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "tZfp66SDWXDi"
      },
      "outputs": [],
      "source": [
        "model_lower = models.Sequential()\n",
        "model_lower.add(layers.Dense(32, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model_lower.add(layers.Dense(20 ,activation='relu'))\n",
        "model_lower.add(layers.Dense(1,activation=keras.activations.softsign))\n",
        "q = 0.05\n",
        "model_lower.compile(loss=lambda y,f: tilted_loss(q,y,f), optimizer=keras.optimizers.SGD())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "z-I3mfPZWcWQ",
        "outputId": "471c7295-6f0a-4d09-8764-eaa8a9b259bc"
      },
      "outputs": [],
      "source": [
        "history_lower=model_lower.fit(x_train, y_train, epochs = 1000, batch_size = 4,validation_data=(x_test,y_test),callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "colab_type": "code",
        "id": "tEL2o4X5Wed9",
        "outputId": "0ab803f9-9659-4c83-b3f2-c7f8a809d27b"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "loss = history_lower.history['loss']\n",
        "val_loss = history_lower.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "colab_type": "code",
        "id": "YrnNqnH6WjAm",
        "outputId": "2ae0872e-a90f-4c27-a25a-69a8149d0aa2"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "plt.scatter(range(len(y_test)),y_test)\n",
        "pred_lower = model_lower.predict(x_test)\n",
        "plt.plot(range(len(y_test)),pred_lower)\n",
        "pred_upper = model_upper.predict(x_test)\n",
        "plt.plot(range(len(y_test)),pred_upper)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "sF_gIsmu9WbE"
      },
      "outputs": [],
      "source": [
        "model_const1 = models.Sequential()\n",
        "model_const1.add(layers.Dense(32, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model_const1.add(layers.Dense(20, activation='relu'))\n",
        "model_const1.add(layers.Dense(1,activation = keras.activations.softsign))\n",
        "q = 0.5\n",
        "model_const1.compile(loss=lambda y,f: tilted_loss(q,y,f), optimizer=keras.optimizers.SGD())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "enzSOTpPLSIx",
        "outputId": "a891e34e-bea6-4a44-c2f3-f6c2da34eee4"
      },
      "outputs": [],
      "source": [
        "history_const1=model_const1.fit(x_train, y_train, epochs = 1000, batch_size = 8,validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "colab_type": "code",
        "id": "IEWN2QTTLaX1",
        "outputId": "657107ee-45bc-441a-a516-a76fd53ce82a"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "loss = history_const1.history['loss']\n",
        "val_loss = history_const1.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "colab_type": "code",
        "id": "RmxbgplWMA5g",
        "outputId": "e38a4f2e-ae7e-4a96-a026-e006dee72d87"
      },
      "outputs": [],
      "source": [
        "  %matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "loss_const = history_const1.history['loss']\n",
        "loss_lalr = history.history['loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss_const, 'r', label='Loss Constant')\n",
        "plt.plot(epochs, loss_lalr, 'b', label='Loss LALR')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylim(0.1,0.3)\n",
        "plt.legend()\n",
        "plt.savefig('quantile_5.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "SsLAJaDIFk0F"
      },
      "outputs": [],
      "source": [
        "model_const2 = models.Sequential()\n",
        "model_const2.add(layers.Dense(32, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model_const2.add(layers.Dense(20, activation='relu'))\n",
        "model_const2.add(layers.Dense(1,activation = keras.activations.softsign))\n",
        "q = 0.05\n",
        "model_const2.compile(loss=lambda y,f: tilted_loss(q,y,f), optimizer=keras.optimizers.SGD())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "VFWSdqMO1UXm",
        "outputId": "fa32a823-ae17-4629-fb86-111c346d69cb"
      },
      "outputs": [],
      "source": [
        "history_const2 =model_const2.fit(x_train, y_train, epochs = 1000, batch_size = 4,validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "colab_type": "code",
        "id": "NDYug0DJ2A9e",
        "outputId": "f5e17231-37b6-48a1-8d95-7d514f629bdd"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "loss = history_const2.history['loss']\n",
        "val_loss = history_const2.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "colab_type": "code",
        "id": "q4opAd6f2stl",
        "outputId": "41e0ee40-1fa3-46d4-b00d-2e632f190c97"
      },
      "outputs": [],
      "source": [
        "  %matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "loss_const = history_const2.history['loss']\n",
        "loss_lalr = history_lower.history['loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss_const, 'r', label='Loss Constant')\n",
        "plt.plot(epochs, loss_lalr, 'b', label='Loss LALR')\n",
        "plt.title('Loss Comparision for 5th Quantile')\n",
        "plt.ylim(0.05,0.1)\n",
        "plt.legend()\n",
        "plt.savefig('quantile_5.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OEoa2yjF25zN"
      },
      "outputs": [],
      "source": [
        "model_const3 = models.Sequential()\n",
        "model_const3.add(layers.Dense(32, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model_const3.add(layers.Dense(20, activation='relu'))\n",
        "model_const3.add(layers.Dense(1,activation = keras.activations.softsign))\n",
        "q = 0.95\n",
        "model_const3.compile(loss=lambda y,f: tilted_loss(q,y,f), optimizer=keras.optimizers.SGD())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "TNnIKyGZ4K4G",
        "outputId": "e0ba39b6-578f-40ae-877b-63bbdf22dc80"
      },
      "outputs": [],
      "source": [
        "history_const3 =model_const3.fit(x_train, y_train, epochs = 1000, batch_size = 4,validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "colab_type": "code",
        "id": "C1t_47NS4bNq",
        "outputId": "5dbc5285-7372-4e15-f1c1-9444c126b099"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "loss = history_const3.history['loss']\n",
        "val_loss = history_const3.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "colab_type": "code",
        "id": "-ivXCM-379ge",
        "outputId": "1df7084d-8e72-4393-a2df-b856412f66d9"
      },
      "outputs": [],
      "source": [
        "  %matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "loss_const = history_const3.history['loss']\n",
        "loss_lalr = history_upper.history['loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss_const, 'r', label='Loss Constant')\n",
        "plt.plot(epochs, loss_lalr, 'b', label='Loss LALR')\n",
        "plt.title('Loss Comparision for 95th Quantile')\n",
        "plt.ylim(0.13,0.2)\n",
        "plt.legend()\n",
        "plt.savefig('quantile_5.png')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "name": "BostonHousing_Lipschitz_Quantile.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "550961419a36abe24d12227d033c554dac4149fde17cf68ad84088aff59c46a1"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
