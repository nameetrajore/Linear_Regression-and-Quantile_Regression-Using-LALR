{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "N2C_If8YUwu5"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.callbacks import LearningRateScheduler\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.utils import shuffle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "c0aTKk2jU_rJ"
      },
      "outputs": [],
      "source": [
        "dataset = pd.read_csv(\"ENB2012_data.csv\")\n",
        "dataset = shuffle(dataset)\n",
        "x_test = dataset.iloc[:50,:]\n",
        "x_train = dataset.iloc[50:,:]\n",
        "y_train = x_train.iloc[:,-2:]\n",
        "y_test = x_test.iloc[:,-2:]\n",
        "x_train = x_train.iloc[:,:-2]\n",
        "x_test = x_test.iloc[:,:-2]\n",
        "x_train_dummy = pd.get_dummies(x_train.iloc[:,-1])\n",
        "x_test_dummy = pd.get_dummies(x_test.iloc[:,-1])\n",
        "x_train['0'] = x_train_dummy.iloc[:,0]\n",
        "x_train['1'] = x_train_dummy.iloc[:,1]\n",
        "x_train['2'] = x_train_dummy.iloc[:,2]\n",
        "x_train['3'] = x_train_dummy.iloc[:,3]\n",
        "x_train['4'] = x_train_dummy.iloc[:,4]\n",
        "x_train['5'] = x_train_dummy.iloc[:,5]\n",
        "x_train.pop('X8')\n",
        "x_test['0'] = x_test_dummy.iloc[:,0]\n",
        "x_test['1'] = x_test_dummy.iloc[:,1]\n",
        "x_test['2'] = x_test_dummy.iloc[:,2]\n",
        "x_test['3'] = x_test_dummy.iloc[:,3]\n",
        "x_test['4'] = x_test_dummy.iloc[:,4]\n",
        "x_test['5'] = x_test_dummy.iloc[:,5]\n",
        "x_test.pop('X8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "nzD3VealYQFD"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(x_train)\n",
        "x_train = scaler.transform(x_train)\n",
        "x_test = scaler.transform(x_test)\n",
        "scaler.fit(y_train)\n",
        "y_train = scaler.transform(y_train)\n",
        "y_test = scaler.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "OP9-Q_BdYrUQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "\n",
        "model.add(layers.Dense(64, activation='relu', input_shape=(x_train.shape[1],)))\n",
        "model.add(layers.Dense(50 ,activation='relu'))\n",
        "model.add(layers.Dense(1,activation=keras.activations.softsign))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "k1yutwSgZOPq"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend as K\n",
        "func = K.function([model.layers[0].input], [model.layers[-2].output])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "0B-UwI5nZPgL"
      },
      "outputs": [],
      "source": [
        "lrs = []\n",
        "K1 = 0.\n",
        "batch_size=32\n",
        "num_classes = 2\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "1aPfOcefZWyg"
      },
      "outputs": [],
      "source": [
        "def lr_schedule(epoch):\n",
        "    global K1\n",
        "\n",
        "    Kz = 0.\n",
        "    \n",
        "    for i in (range((len(x_train) - 1) // batch_size + 1)):\n",
        "      start_i = i * batch_size\n",
        "      end_i = start_i + batch_size\n",
        "      xb = x_train[start_i:end_i]\n",
        "    \n",
        "      tmp = np.array(func([xb]))\n",
        "      activ = np.linalg.norm(tmp)\n",
        "      \n",
        "      if activ > Kz:\n",
        "          Kz = activ\n",
        "    print(\"The value of K_z is \",Kz)\n",
        "    K1 = (1/batch_size)*(Kz)*max(q,1-q)*(1/num_classes)\n",
        "    lr = 1 / K1\n",
        "    lrs.append(lr)\n",
        "    print('Epoch', epoch, 'LR =', lr)\n",
        "    return lr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "-u9ZKjnYZbjV"
      },
      "outputs": [],
      "source": [
        "lr_scheduler = LearningRateScheduler(lr_schedule)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "_iKFRF7FZeZj"
      },
      "outputs": [],
      "source": [
        "import tensorflow.keras.backend as K\n",
        "def tilted_loss(q,y,f):\n",
        "    e = (y-f)\n",
        "    return K.mean(K.maximum(q*e, (q-1)*e), axis=-1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "QRtotTbfZggx"
      },
      "outputs": [],
      "source": [
        "q = 0.05\n",
        "model.compile(loss=lambda y,f: tilted_loss(q,y,f), optimizer=keras.optimizers.SGD())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "1G0_RHTJZkWx",
        "outputId": "294b7f8c-bccd-4812-9514-0beee6ff6252"
      },
      "outputs": [],
      "source": [
        "history=model.fit(x_train, y_train, epochs = 1000, batch_size = 32,validation_data=(x_test,y_test),callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "colab_type": "code",
        "id": "AMAx0JOiZpFs",
        "outputId": "c72592a5-840e-40cb-d04c-ab8490dd6a1b"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "BiP7tVkUbUXc",
        "outputId": "cf418d88-7226-4815-fcbe-e83c956d03d2"
      },
      "outputs": [],
      "source": [
        "q = 0.05\n",
        "model.compile(loss=lambda y,f: tilted_loss(q,y,f), optimizer=keras.optimizers.SGD())\n",
        "history_const=model.fit(x_train, y_train, epochs = 1000, batch_size = 32,validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "colab_type": "code",
        "id": "qmUDfY2rcYmQ",
        "outputId": "f3915aa9-e2c7-442b-9347-ebaf4054057b"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "loss = history_const.history['loss']\n",
        "val_loss = history_const.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "colab_type": "code",
        "id": "BhvC0zpiedog",
        "outputId": "db8b7a06-7caf-487d-bb96-8cad61eef97d"
      },
      "outputs": [],
      "source": [
        "  %matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "loss_const = history_const.history['val_loss']\n",
        "loss_lalr = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss_const, 'r', label='Loss Constant')\n",
        "plt.plot(epochs, loss_lalr, 'b', label='Loss LALR')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylim(0,0.1)\n",
        "plt.legend()\n",
        "plt.savefig('quantile_5.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "uQbLONEbeu-z",
        "outputId": "98442c85-f090-4238-c1c4-2a07ac5b8b22"
      },
      "outputs": [],
      "source": [
        "q = 0.95\n",
        "model.compile(loss=lambda y,f: tilted_loss(q,y,f), optimizer=keras.optimizers.SGD())\n",
        "history=model.fit(x_train, y_train, epochs = 1000, batch_size = 32,validation_data=(x_test,y_test),callbacks=[lr_scheduler])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "colab_type": "code",
        "id": "BiZjgVNYs2nD",
        "outputId": "2d8f5d05-fb98-40da-e0d3-2cd18eeb858b"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "colab_type": "code",
        "id": "kAwBGUsktZFl",
        "outputId": "04c6f003-2154-46ba-ef51-7e9576ec98c8"
      },
      "outputs": [],
      "source": [
        "q = 0.95\n",
        "model.compile(loss=lambda y,f: tilted_loss(q,y,f), optimizer=keras.optimizers.SGD())\n",
        "history_const=model.fit(x_train, y_train, epochs = 1000, batch_size = 32,validation_data=(x_test,y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "colab_type": "code",
        "id": "XqYAJ0xVttpE",
        "outputId": "b0c0aa92-7ec9-46bf-d276-1bed4fee2fda"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "loss = history_const.history['loss']\n",
        "val_loss = history_const.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss, 'r', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "plt.savefig('loss.png')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "colab_type": "code",
        "id": "onXgYQ5tuQ1g",
        "outputId": "468744d8-633c-4a3c-89a7-763f46fddd68"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "loss_const = history_const.history['val_loss']\n",
        "loss_lalr = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "plt.plot(epochs, loss_const, 'r', label='Loss Constant')\n",
        "plt.plot(epochs, loss_lalr, 'b', label='Loss LALR')\n",
        "plt.title('Training and validation loss')\n",
        "plt.ylim(0.08,0.2)\n",
        "plt.legend()\n",
        "plt.savefig('quantile_5.png')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyOmU56Ag1mHAwnlSYFhTG8z",
      "include_colab_link": true,
      "name": "EnergyEfficiency_Quantile_Lipschitz",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
